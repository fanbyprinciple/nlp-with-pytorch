# Chapter 1 : Introduction

https://www.kaggle.com/fanbyprinciple/nlp-with-pytorch-chapter-1/edit

Observations
Targets
Model
Parameters
Predictions
Loss function

one hot encoded vector

TF representation of a phrase, sentence or document is simple the sum of the one hot representations of its constituent words. 

We denote the TF of a word w by TF(w)

Term frequency representation:
![](tf_representation.png)

### TF IDF Representation

Term frequency might tell us about frequency of occurance but it doesnt tell us about how important occurance of a word is, it is looked after bu Tf-IDf representation

![](tfidf_representation.png)

page 15


